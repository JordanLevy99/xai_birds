{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import PIL.Image as Image\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "from captum.attr import GuidedGradCam\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "from bird_dataset import *\n",
    "from XAI_birds_dataloader import *\n",
    "from tqdm import tqdm\n",
    "from models.multi_task_model import *\n",
    "from XAI_birds_dataloader import *\n",
    "from XAI_BirdAttribute_dataloader import *\n",
    "\n",
    "from download import *\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download = True\n",
    "# id = '156fCp5_VvRfnyHSCBCXhInSE9TxEqDaY'\n",
    "# destination = '../cub.zip'\n",
    "# if download:\n",
    "#     download_file_from_google_drive(id, destination)\n",
    "# # shutil.unpack_archive('../cub.zip', '../CUB_200_2011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = BirdDataset(preload=True, attr_file='attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16_bn(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_bird_dataset = Bird_Attribute_Loader(bd, attrs=['has_breast_pattern'], species=False, transform=trans, train=True)\n",
    "val_bird_dataset = Bird_Attribute_Loader(bd, attrs=['has_breast_pattern'], species=False, transform=trans, train=False, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_bird_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskModel(vgg16, train_bird_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# If 'cuda:0' is printed, it means GPU is available.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "batch_size = 1\n",
    "trainloader = DataLoader(train_bird_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_bird_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loss_func = MultiTaskLossWrapper().to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = train_bird_dataset[0]\n",
    "# inputs, labels = data['image'].cuda(), torch.LongTensor(data['labels']).cuda()\n",
    "# outputs =  model(inputs.reshape((1, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    99] avg mini-batch loss: 1.505\n",
      "[epoch: 0, i:   199] avg mini-batch loss: 1.092\n",
      "[epoch: 0, i:   299] avg mini-batch loss: 1.128\n",
      "[epoch: 0, i:   399] avg mini-batch loss: 0.894\n",
      "[epoch: 0, i:   499] avg mini-batch loss: 0.945\n",
      "[epoch: 0, i:   599] avg mini-batch loss: 1.018\n",
      "[epoch: 0, i:   699] avg mini-batch loss: 0.890\n",
      "[epoch: 0, i:   799] avg mini-batch loss: 1.109\n",
      "[epoch: 0, i:   899] avg mini-batch loss: 1.134\n",
      "[epoch: 0, i:   999] avg mini-batch loss: 0.932\n",
      "[epoch: 0, i:  1099] avg mini-batch loss: 0.850\n",
      "[epoch: 0, i:  1199] avg mini-batch loss: 0.891\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "avg_losses = []\n",
    "avg_val_losses = []\n",
    "epochs = 50\n",
    "print_freq = 100\n",
    "val_acc = []\n",
    "if len(train_bird_dataset.class_dict) > 1: plural = 's'\n",
    "else: plural = ''\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "#         print(\"LABELS:\",data['labels'])\n",
    "        inputs, labels = data['image'], torch.LongTensor(data[f'labels'])\n",
    "\n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = model(inputs)\n",
    "        # print('outputs came')\n",
    "        # print(\"OUTPUTS:\",outputs) \n",
    "        # break\n",
    "        loss = loss_func(outputs, labels)\n",
    "        # print(loss)\n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "#         print('running loss', running_loss)\n",
    "#         print(outputs)\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    avg_losses.append(avg_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        num_correct=0\n",
    "        val_losses = []\n",
    "        data_iter = iter(valloader)\n",
    "        for val_data in data_iter:\n",
    "            val_inputs, val_labels = val_data['image'].cuda(), torch.LongTensor(val_data[f'labels']).cuda()\n",
    "            val_outputs = model(val_inputs)\n",
    "            opt.zero_grad() #zero the parameter gradients\n",
    "            val_predicted = [torch.max(i, 1)[1] for i in val_outputs]\n",
    "            num_correct += sum(np.array(val_labels.cpu())==np.array(val_predicted))\n",
    "            val_losses.append(loss_func(val_outputs, val_labels).item())\n",
    "        acc = num_correct/(len(data_iter)*batch_size*len(val_labels))\n",
    "        val_acc.append(acc)\n",
    "        print('Validation accuracy:',acc)\n",
    "        print('Average validation loss:',np.mean(val_losses))\n",
    "        avg_val_losses.append(np.mean(val_losses))\n",
    "    model.train()\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_str = '__'.join(list(train_bird_dataset.class_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_loss(avg_losses, avg_val_losses, f_label_size=15, f_title_size=18, f_ticks_size=12):\n",
    "    plt.plot(avg_losses)\n",
    "    plt.plot(avg_val_losses)\n",
    "    plt.xlabel('Epochs', fontsize=f_label_size)\n",
    "    plt.ylabel('Loss', fontsize=f_label_size)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend(['Training Loss', 'Validation Loss']);\n",
    "    plt.savefig(f'../figures/{task_str}_{epochs}_epoch_train_val_loss.png', dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss(avg_losses, avg_val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../models/{task_str}_{epochs}_epoch_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c6f662cde1eb1592601abbdd2d729bcfa9367260f8aa16e06151e60a3b87cd8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

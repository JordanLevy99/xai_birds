{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import PIL.Image as Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')\n",
    "from bird_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = BirdDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8760, 5015, 4372, ..., 2085, 1285, 7390])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'../CUB_200_2011/classes-subset.txt') as f:\n",
    "#     for line in f.readlines():\n",
    "#         print(line.split(' '))\n",
    "# #     try:class_dict = {int(line.split(' ')[0]):i for i, line in enumerate(f.readlines())}\n",
    "# #     except: \n",
    "# #         print(int(line.split(' ')))\n",
    "# #         raise ValueErro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filepath': '001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg',\n",
       " 'class_label': 1,\n",
       " 'bounding_box': [60.0, 27.0, 325.0, 304.0],\n",
       " 'parts': {'beak': [312.0, 182.0],\n",
       "  'crown': [186.0, 45.0],\n",
       "  'forehead': [247.0, 79.0],\n",
       "  'nape': [100.0, 221.0],\n",
       "  'right eye': [183.0, 101.0],\n",
       "  'throat': [215.0, 194.0]},\n",
       " 'attributes': ['has_bill_shape::hooked_seabird',\n",
       "  'has_head_pattern::masked',\n",
       "  'has_throat_color::buff',\n",
       "  'has_eye_color::brown',\n",
       "  'has_bill_length::longer_than_head',\n",
       "  'has_forehead_color::white',\n",
       "  'has_nape_color::buff',\n",
       "  'has_size::large_(16_-_32_in)',\n",
       "  'has_shape::long-legged-like',\n",
       "  'has_primary_color::buff',\n",
       "  'has_bill_color::buff',\n",
       "  'has_crown_color::buff']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XAI_Birds_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, bd:BirdDataset, subset=True, transform=None, train=True):\n",
    "        self.bd = bd\n",
    "        self.transform = transform\n",
    "        self.subset = subset\n",
    "        self.train = train\n",
    "        if self.train: self.train_test_indices = self.bd.train_indices\n",
    "        else: self.train_test_indices = self.bd.test_indices\n",
    "        \n",
    "        if self.subset: self.class_dict = self._set_classes('classes-subset')\n",
    "        else: self.class_dict = self._set_classes('classes')\n",
    "        self.images = self.load_images()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_id = list(self.images.keys())[idx]\n",
    "        img_path = os.path.join(self.bd.img_dir, self.images[img_id]['filepath'])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.class_dict[self.images[img_id]['class_label']]\n",
    "        sample = {'image': image, 'label':label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "        return sample\n",
    "    def _set_classes(self, fname):\n",
    "        with open(f'../CUB_200_2011/{fname}.txt') as f:\n",
    "            class_dict = {int(line.split(' ')[0]):i for i, line in enumerate(f.readlines())}\n",
    "        return class_dict\n",
    "    \n",
    "    def load_images(self):\n",
    "        images = {}\n",
    "        for key in self.bd.images:\n",
    "            class_label = self.bd.images[key]['class_label']\n",
    "            if class_label in list(self.class_dict.keys()) and class_label in self.train_test_indices:\n",
    "                images[key] = self.bd.images[key] \n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_bird_dataset = XAI_Birds_Dataset(bd, transform=transf, train=True)\n",
    "val_bird_dataset = XAI_Birds_Dataset(bd, transform=transf, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_bird_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1833"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_bird_dataset) + len(val_bird_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_bird_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16_bn(pretrained=False)\n",
    "num_feats = vgg16.classifier[6].in_features\n",
    "features = list(vgg16.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_feats, len(train_bird_dataset.class_dict))])\n",
    "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_feats = vgg16.classifier[6].in_features\n",
    "# features = list(vgg16.classifier.children())[:-1]\n",
    "# features.extend([nn.Linear(num_feats, len(train_bird_dataset.class_dict))])\n",
    "# vgg16.classifier = nn.Sequential(*features) # Replace the model classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    vgg16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = list(range(len(bird_dataset)))\n",
    "# train_idx = np.random.choice(indices, size=int(len(bird_dataset)*.8), replace=False)\n",
    "# test_idx = list(set(indices) - set(train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainloader = DataLoader(train_bird_dataset, batch_size=batch_size)\n",
    "valloader = DataLoader(val_bird_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(trainloader, 0):\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_bird_dataset) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    99] avg mini-batch loss: 3.736\n",
      "Average validation loss: 4.957454523343719\n",
      "[epoch: 0, i:   199] avg mini-batch loss: 3.446\n",
      "Average validation loss: 3.5564093670148527\n",
      "[epoch: 0, i:   299] avg mini-batch loss: 3.445\n",
      "Average validation loss: 3.4948744345247076\n",
      "[epoch: 1, i:    99] avg mini-batch loss: 3.298\n",
      "Average validation loss: 7.420080747497216\n",
      "[epoch: 1, i:   199] avg mini-batch loss: 2.893\n",
      "Average validation loss: 4.610361902901296\n",
      "[epoch: 1, i:   299] avg mini-batch loss: 3.335\n",
      "Average validation loss: 3.5802922382783353\n",
      "[epoch: 2, i:    99] avg mini-batch loss: 3.479\n",
      "Average validation loss: 3.6638265941919905\n",
      "[epoch: 2, i:   199] avg mini-batch loss: 2.977\n",
      "Average validation loss: 6.4106350266531615\n",
      "[epoch: 2, i:   299] avg mini-batch loss: 3.194\n",
      "Average validation loss: 3.6666982763268976\n",
      "[epoch: 3, i:    99] avg mini-batch loss: 3.438\n",
      "Average validation loss: 3.7532945697227222\n",
      "[epoch: 3, i:   199] avg mini-batch loss: 2.968\n",
      "Average validation loss: 5.496786230065849\n",
      "[epoch: 3, i:   299] avg mini-batch loss: 3.083\n",
      "Average validation loss: 3.7762318139665583\n",
      "[epoch: 4, i:    99] avg mini-batch loss: 3.399\n",
      "Average validation loss: 3.8554609304063776\n",
      "[epoch: 4, i:   199] avg mini-batch loss: 3.182\n",
      "Average validation loss: 7.333838414610102\n",
      "[epoch: 4, i:   299] avg mini-batch loss: 2.914\n",
      "Average validation loss: 3.8912313680970265\n",
      "[epoch: 5, i:    99] avg mini-batch loss: 3.366\n",
      "Average validation loss: 3.8634629303149963\n",
      "[epoch: 5, i:   199] avg mini-batch loss: 3.205\n",
      "Average validation loss: 7.119121776537948\n",
      "[epoch: 5, i:   299] avg mini-batch loss: 2.654\n",
      "Average validation loss: 3.9263598195622476\n",
      "[epoch: 6, i:    99] avg mini-batch loss: 3.336\n",
      "Average validation loss: 3.9598965403738986\n",
      "[epoch: 6, i:   199] avg mini-batch loss: 3.508\n",
      "Average validation loss: 3.958547889516595\n",
      "[epoch: 6, i:   299] avg mini-batch loss: 3.419\n",
      "Average validation loss: 3.9824022550261424\n",
      "[epoch: 7, i:    99] avg mini-batch loss: 3.332\n",
      "Average validation loss: 4.014153984155548\n",
      "[epoch: 7, i:   199] avg mini-batch loss: 3.482\n",
      "Average validation loss: 4.043056016557672\n",
      "[epoch: 7, i:   299] avg mini-batch loss: 3.403\n",
      "Average validation loss: 4.040011084481572\n",
      "[epoch: 8, i:    99] avg mini-batch loss: 3.328\n",
      "Average validation loss: 4.081376541866345\n",
      "[epoch: 8, i:   199] avg mini-batch loss: 3.459\n",
      "Average validation loss: 4.139940524369143\n",
      "[epoch: 8, i:   299] avg mini-batch loss: 3.390\n",
      "Average validation loss: 4.107073333825958\n",
      "[epoch: 9, i:    99] avg mini-batch loss: 3.326\n",
      "Average validation loss: 4.147327208786868\n",
      "[epoch: 9, i:   199] avg mini-batch loss: 3.439\n",
      "Average validation loss: 4.180683805701438\n",
      "[epoch: 9, i:   299] avg mini-batch loss: 3.378\n",
      "Average validation loss: 4.185398235749663\n",
      "[epoch: 10, i:    99] avg mini-batch loss: 3.324\n",
      "Average validation loss: 4.224407453215524\n",
      "[epoch: 10, i:   199] avg mini-batch loss: 3.421\n",
      "Average validation loss: 4.24557717462604\n",
      "[epoch: 10, i:   299] avg mini-batch loss: 3.367\n",
      "Average validation loss: 4.249078380927611\n",
      "[epoch: 11, i:    99] avg mini-batch loss: 3.323\n",
      "Average validation loss: 4.281893494423856\n",
      "[epoch: 11, i:   199] avg mini-batch loss: 3.406\n",
      "Average validation loss: 4.327623420886779\n",
      "[epoch: 11, i:   299] avg mini-batch loss: 3.358\n",
      "Average validation loss: 4.308642098073209\n",
      "[epoch: 12, i:    99] avg mini-batch loss: 3.322\n",
      "Average validation loss: 4.332484673917963\n",
      "[epoch: 12, i:   199] avg mini-batch loss: 3.392\n",
      "Average validation loss: 4.364114032702499\n",
      "[epoch: 12, i:   299] avg mini-batch loss: 3.350\n",
      "Average validation loss: 4.367236812462967\n",
      "[epoch: 13, i:    99] avg mini-batch loss: 3.321\n",
      "Average validation loss: 4.377399926774957\n",
      "[epoch: 13, i:   199] avg mini-batch loss: 3.380\n",
      "Average validation loss: 4.473572066660678\n",
      "[epoch: 13, i:   299] avg mini-batch loss: 3.343\n",
      "Average validation loss: 4.420292270317506\n",
      "[epoch: 14, i:    99] avg mini-batch loss: 3.320\n",
      "Average validation loss: 4.473295281442364\n",
      "[epoch: 14, i:   199] avg mini-batch loss: 3.369\n",
      "Average validation loss: 4.479990418037672\n",
      "[epoch: 14, i:   299] avg mini-batch loss: 3.337\n",
      "Average validation loss: 4.470075698381059\n",
      "[epoch: 15, i:    99] avg mini-batch loss: 3.319\n",
      "Average validation loss: 4.494075212585792\n",
      "[epoch: 15, i:   199] avg mini-batch loss: 3.360\n",
      "Average validation loss: 4.564572398582201\n",
      "[epoch: 15, i:   299] avg mini-batch loss: 3.332\n",
      "Average validation loss: 4.583157357205166\n",
      "[epoch: 16, i:    99] avg mini-batch loss: 3.318\n",
      "Average validation loss: 4.552744297499068\n",
      "[epoch: 16, i:   199] avg mini-batch loss: 3.352\n",
      "Average validation loss: 4.563036302502236\n",
      "[epoch: 16, i:   299] avg mini-batch loss: 3.327\n",
      "Average validation loss: 4.5694751632347534\n",
      "[epoch: 17, i:    99] avg mini-batch loss: 3.317\n",
      "Average validation loss: 4.588553198267904\n",
      "[epoch: 17, i:   199] avg mini-batch loss: 3.344\n",
      "Average validation loss: 4.619595120462139\n",
      "[epoch: 17, i:   299] avg mini-batch loss: 3.322\n",
      "Average validation loss: 4.619478525740377\n",
      "[epoch: 18, i:    99] avg mini-batch loss: 3.316\n",
      "Average validation loss: 4.663025475619884\n",
      "[epoch: 18, i:   199] avg mini-batch loss: 3.338\n",
      "Average validation loss: 4.719703642170081\n",
      "[epoch: 18, i:   299] avg mini-batch loss: 3.294\n",
      "Average validation loss: 4.688126087188721\n",
      "[epoch: 19, i:    99] avg mini-batch loss: 3.309\n",
      "Average validation loss: 4.663963939366716\n",
      "[epoch: 19, i:   199] avg mini-batch loss: 3.329\n",
      "Average validation loss: 4.755563553799404\n",
      "[epoch: 19, i:   299] avg mini-batch loss: 3.150\n",
      "Average validation loss: 4.842011264200961\n",
      "[epoch: 20, i:    99] avg mini-batch loss: 3.298\n",
      "Average validation loss: 4.704235039400251\n",
      "[epoch: 20, i:   199] avg mini-batch loss: 3.317\n",
      "Average validation loss: 4.738512971428003\n",
      "[epoch: 20, i:   299] avg mini-batch loss: 3.352\n",
      "Average validation loss: 4.739569283603283\n",
      "[epoch: 21, i:    99] avg mini-batch loss: 3.298\n",
      "Average validation loss: 4.736830143446333\n",
      "[epoch: 21, i:   199] avg mini-batch loss: 3.313\n",
      "Average validation loss: 4.768460289815838\n",
      "[epoch: 21, i:   299] avg mini-batch loss: 3.344\n",
      "Average validation loss: 4.8052119726545355\n",
      "[epoch: 22, i:    99] avg mini-batch loss: 3.300\n",
      "Average validation loss: 4.778812547748008\n",
      "[epoch: 22, i:   199] avg mini-batch loss: 3.310\n",
      "Average validation loss: 4.82139729381947\n",
      "[epoch: 22, i:   299] avg mini-batch loss: 3.337\n",
      "Average validation loss: 4.825038020530443\n",
      "[epoch: 23, i:    99] avg mini-batch loss: 3.301\n",
      "Average validation loss: 4.834499064456211\n",
      "[epoch: 23, i:   199] avg mini-batch loss: 3.265\n",
      "Average validation loss: 6.215925607788429\n",
      "[epoch: 23, i:   299] avg mini-batch loss: 2.559\n",
      "Average validation loss: 4.902508387404882\n",
      "[epoch: 24, i:    99] avg mini-batch loss: 3.278\n",
      "Average validation loss: 4.84165645449349\n",
      "[epoch: 24, i:   199] avg mini-batch loss: 3.292\n",
      "Average validation loss: 4.85719535591897\n",
      "[epoch: 24, i:   299] avg mini-batch loss: 3.096\n",
      "Average validation loss: 9.338033440407742\n",
      "[epoch: 25, i:    99] avg mini-batch loss: 3.270\n",
      "Average validation loss: 4.896873420543885\n",
      "[epoch: 25, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 4.889331222919935\n",
      "[epoch: 25, i:   299] avg mini-batch loss: 3.398\n",
      "Average validation loss: 4.918659906708792\n",
      "[epoch: 26, i:    99] avg mini-batch loss: 3.274\n",
      "Average validation loss: 4.935422007957201\n",
      "[epoch: 26, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 4.930068423239033\n",
      "[epoch: 26, i:   299] avg mini-batch loss: 3.383\n",
      "Average validation loss: 4.927220162380947\n",
      "[epoch: 27, i:    99] avg mini-batch loss: 3.278\n",
      "Average validation loss: 4.954228379753198\n",
      "[epoch: 27, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 4.958543434571684\n",
      "[epoch: 27, i:   299] avg mini-batch loss: 3.370\n",
      "Average validation loss: 4.957849588287011\n",
      "[epoch: 28, i:    99] avg mini-batch loss: 3.281\n",
      "Average validation loss: 4.978632230437204\n",
      "[epoch: 28, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 4.991551463523607\n",
      "[epoch: 28, i:   299] avg mini-batch loss: 3.358\n",
      "Average validation loss: 5.000795209005977\n",
      "[epoch: 29, i:    99] avg mini-batch loss: 3.283\n",
      "Average validation loss: 5.021218294508002\n",
      "[epoch: 29, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 5.022360549883896\n",
      "[epoch: 29, i:   299] avg mini-batch loss: 3.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss: 5.026277483179328\n",
      "[epoch: 30, i:    99] avg mini-batch loss: 3.286\n",
      "Average validation loss: 5.132549366254485\n",
      "[epoch: 30, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 5.045573652460334\n",
      "[epoch: 30, i:   299] avg mini-batch loss: 3.340\n",
      "Average validation loss: 5.054790620053752\n",
      "[epoch: 31, i:    99] avg mini-batch loss: 3.288\n",
      "Average validation loss: 5.1139015079884045\n",
      "[epoch: 31, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 5.093228393726134\n",
      "[epoch: 31, i:   299] avg mini-batch loss: 3.332\n",
      "Average validation loss: 5.08380986867326\n",
      "[epoch: 32, i:    99] avg mini-batch loss: 3.289\n",
      "Average validation loss: 5.095916983786593\n",
      "[epoch: 32, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 5.101016489307532\n",
      "[epoch: 32, i:   299] avg mini-batch loss: 3.325\n",
      "Average validation loss: 5.113647112685643\n",
      "[epoch: 33, i:    99] avg mini-batch loss: 3.290\n",
      "Average validation loss: 5.144732550288854\n",
      "[epoch: 33, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 5.13344620586781\n",
      "[epoch: 33, i:   299] avg mini-batch loss: 3.319\n",
      "Average validation loss: 5.135795041416468\n",
      "[epoch: 34, i:    99] avg mini-batch loss: 3.291\n",
      "Average validation loss: 5.160930446024691\n",
      "[epoch: 34, i:   199] avg mini-batch loss: 3.283\n",
      "Average validation loss: 5.161663478679872\n",
      "[epoch: 34, i:   299] avg mini-batch loss: 3.314\n",
      "Average validation loss: 5.163288320048472\n",
      "[epoch: 35, i:    99] avg mini-batch loss: 3.292\n",
      "Average validation loss: 5.215218318982071\n",
      "[epoch: 35, i:   199] avg mini-batch loss: 3.281\n",
      "Average validation loss: 5.2168363024679465\n",
      "[epoch: 35, i:   299] avg mini-batch loss: 2.651\n",
      "Average validation loss: 6.248050770063079\n",
      "[epoch: 36, i:    99] avg mini-batch loss: 3.273\n",
      "Average validation loss: 5.1943955796488215\n",
      "[epoch: 36, i:   199] avg mini-batch loss: 3.266\n",
      "Average validation loss: 5.20626712113284\n",
      "[epoch: 36, i:   299] avg mini-batch loss: 2.939\n",
      "Average validation loss: 11.952646812696136\n",
      "[epoch: 37, i:    99] avg mini-batch loss: 3.262\n",
      "Average validation loss: 5.215939698594339\n",
      "[epoch: 37, i:   199] avg mini-batch loss: 3.256\n",
      "Average validation loss: 5.224616473980165\n",
      "[epoch: 37, i:   299] avg mini-batch loss: 3.377\n",
      "Average validation loss: 5.244982976591989\n",
      "[epoch: 38, i:    99] avg mini-batch loss: 3.265\n",
      "Average validation loss: 5.243257752965006\n",
      "[epoch: 38, i:   199] avg mini-batch loss: 3.259\n",
      "Average validation loss: 5.263288926542475\n",
      "[epoch: 38, i:   299] avg mini-batch loss: 3.363\n",
      "Average validation loss: 5.260888689019707\n",
      "[epoch: 39, i:    99] avg mini-batch loss: 3.269\n",
      "Average validation loss: 5.266211975826306\n",
      "[epoch: 39, i:   199] avg mini-batch loss: 3.261\n",
      "Average validation loss: 5.282341153434153\n",
      "[epoch: 39, i:   299] avg mini-batch loss: 3.276\n",
      "Average validation loss: 9.79258771960655\n",
      "[epoch: 40, i:    99] avg mini-batch loss: 3.265\n",
      "Average validation loss: 5.286826985605647\n",
      "[epoch: 40, i:   199] avg mini-batch loss: 3.257\n",
      "Average validation loss: 5.3125403650691\n",
      "[epoch: 40, i:   299] avg mini-batch loss: 3.346\n",
      "Average validation loss: 5.2983866648727584\n",
      "[epoch: 41, i:    99] avg mini-batch loss: 3.268\n",
      "Average validation loss: 5.316029934400923\n",
      "[epoch: 41, i:   199] avg mini-batch loss: 3.259\n",
      "Average validation loss: 5.32399893878551\n",
      "[epoch: 41, i:   299] avg mini-batch loss: 3.336\n",
      "Average validation loss: 5.322081881962466\n",
      "[epoch: 42, i:    99] avg mini-batch loss: 3.271\n",
      "Average validation loss: 5.326968412720755\n",
      "[epoch: 42, i:   199] avg mini-batch loss: 3.261\n",
      "Average validation loss: 5.337783234842708\n",
      "[epoch: 42, i:   299] avg mini-batch loss: 3.328\n",
      "Average validation loss: 5.355142523733417\n",
      "[epoch: 43, i:    99] avg mini-batch loss: 3.271\n",
      "Average validation loss: 5.356422027845062\n",
      "[epoch: 43, i:   199] avg mini-batch loss: 3.262\n",
      "Average validation loss: 5.36654489495781\n",
      "[epoch: 43, i:   299] avg mini-batch loss: 3.161\n",
      "Average validation loss: 13.203721710805143\n",
      "[epoch: 44, i:    99] avg mini-batch loss: 3.260\n",
      "Average validation loss: 5.38700758473257\n",
      "[epoch: 44, i:   199] avg mini-batch loss: 3.252\n",
      "Average validation loss: 5.382815468177367\n",
      "[epoch: 44, i:   299] avg mini-batch loss: 3.238\n",
      "Average validation loss: 6.637932021966141\n",
      "[epoch: 45, i:    99] avg mini-batch loss: 3.248\n",
      "Average validation loss: 5.393849201416701\n",
      "[epoch: 45, i:   199] avg mini-batch loss: 3.242\n",
      "Average validation loss: 5.397978739792041\n",
      "[epoch: 45, i:   299] avg mini-batch loss: 3.319\n",
      "Average validation loss: 5.413431301545561\n",
      "[epoch: 46, i:    99] avg mini-batch loss: 3.253\n",
      "Average validation loss: 5.411652377482211\n",
      "[epoch: 46, i:   199] avg mini-batch loss: 3.246\n",
      "Average validation loss: 5.4283260388320755\n",
      "[epoch: 46, i:   299] avg mini-batch loss: 3.313\n",
      "Average validation loss: 5.430014074518439\n",
      "[epoch: 47, i:    99] avg mini-batch loss: 3.258\n",
      "Average validation loss: 5.447370084483972\n",
      "[epoch: 47, i:   199] avg mini-batch loss: 3.249\n",
      "Average validation loss: 5.441855800285768\n",
      "[epoch: 47, i:   299] avg mini-batch loss: 3.307\n",
      "Average validation loss: 5.45748587404744\n",
      "[epoch: 48, i:    99] avg mini-batch loss: 3.262\n",
      "Average validation loss: 5.445375683602323\n",
      "[epoch: 48, i:   199] avg mini-batch loss: 3.252\n",
      "Average validation loss: 5.453647281346696\n",
      "[epoch: 48, i:   299] avg mini-batch loss: 3.302\n",
      "Average validation loss: 5.465189328354396\n",
      "[epoch: 49, i:    99] avg mini-batch loss: 3.266\n",
      "Average validation loss: 5.472996095593056\n",
      "[epoch: 49, i:   199] avg mini-batch loss: 3.255\n",
      "Average validation loss: 5.487909033057395\n",
      "[epoch: 49, i:   299] avg mini-batch loss: 3.298\n",
      "Average validation loss: 5.483974231762833\n",
      "Finished Training.\n",
      "CPU times: user 17min 17s, sys: 2.53 s, total: 17min 19s\n",
      "Wall time: 17min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "avg_losses = []\n",
    "avg_val_losses = []\n",
    "epochs = 50\n",
    "print_freq = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data['image'], data['label']\n",
    "\n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = vgg16(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "#         print(outputs)\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            vgg16.eval()\n",
    "            with torch.no_grad():\n",
    "                val_losses = []\n",
    "                data_iter = iter(valloader)\n",
    "                for val_data in data_iter:\n",
    "                    val_inputs, val_labels = val_data['image'].cuda(), val_data['label'].cuda()\n",
    "#                     print('val inputs: ',val_inputs.size())\n",
    "#                     print('val labels: ',val_labels)\n",
    "#                     print('inputs: ',inputs.size())\n",
    "                    val_outputs = vgg16(val_inputs)\n",
    "#                     print('val outputs: ',val_outputs)\n",
    "#                     print('val loss: ',nn.CrossEntropyLoss()(val_outputs, val_labels))\n",
    "                    opt.zero_grad() #zero the parameter gradients\n",
    "                    val_losses.append(loss_func(val_outputs, val_labels).item())\n",
    "                print('Average validation loss:',np.mean(val_losses))\n",
    "                avg_val_losses.append(np.mean(val_losses))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "            vgg16.train()\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16.eval(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb6d730940>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.plot(avg_val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), '../models/vgg16_31_class_50_epoch_4_batch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/jdlevy/anaconda3/envs/py38/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Captum Model Explainability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_classes = {v: k for k, v in }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The function to show an image.\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # Unnormalize.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bird_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3fc92c9712c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check several images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for i in range(len(dataiter)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Check several images.\n",
    "dataiter = iter(val_loader)\n",
    "batch_size = 4\n",
    "# for i in range(len(dataiter)):\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print(labels)\n",
    "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(\"Ground Truth:\", [classes[labels[i]] for i in range(batch_size)])\n",
    "print(\"Predicted:\",[classes[predicted[i]] for i in range(batch_size)])\n",
    "print(\"Accuracy:\",sum(np.array(labels)==np.array(predicted.cpu()))/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import GuidedGradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv = vgg16.features[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = GuidedGradCam(vgg16, last_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = val_bird_dataset[0]['image'], val_bird_dataset[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdlevy/anaconda3/envs/py38/lib/python3.8/site-packages/captum/_utils/gradient.py:53: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 3-dimensional input of size [3, 224, 224] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4c7cc5c0211d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/captum/attr/_core/guided_grad_cam.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, target, additional_forward_args, interpolate_mode, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mis_inputs_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         grad_cam_attr = self.grad_cam.attribute.__wrapped__(\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_cam\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/captum/attr/_core/layer/grad_cam.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, target, additional_forward_args, attribute_to_layer_input, relu_attributions)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Returns gradient of output with respect to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# hidden layer and hidden layer evaluated at each input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         layer_gradients, layer_evals = compute_layer_gradients_and_eval(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_layer_gradients_and_eval\u001b[0;34m(forward_fn, layer, inputs, target_ind, additional_forward_args, gradient_neuron_selector, device_ids, attribute_to_layer_input, output_fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# saved_layer is a dictionary mapping device to a tuple of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;31m# layer evaluations on that device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         saved_layer, output = _forward_layer_distributed_eval(\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36m_forward_layer_distributed_eval\u001b[0;34m(forward_fn, inputs, layer, target_ind, additional_forward_args, attribute_to_layer_input, forward_hook_with_return)\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0msingle_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[0;32m--> 295\u001b[0;31m         output = _run_forward(\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0madditional_forward_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_additional_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     output = forward_func(\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 415\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 3-dimensional input of size [3, 224, 224] instead"
     ]
    }
   ],
   "source": [
    "gc.attribute(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import PIL.Image as Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "from bird_dataset import *\n",
    "from XAI_birds_dataloader import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide\n",
    "# from fastai.vision.all import *\n",
    "# from fastai.text.all import *\n",
    "# from fastai.collab import *\n",
    "# from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = BirdDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird_Attribute_Loader(XAI_Birds_Dataset):\n",
    "    '''\n",
    "    Can be combined with Bill Shape Class into one general class with attribute self.attr = 'has_wing_color'\n",
    "    '''\n",
    "    def __init__(self, bd:BirdDataset, attrs, subset=True, transform=None, train=True, val=False, random_seed=42):\n",
    "        XAI_Birds_Dataset.__init__(self, bd, subset=subset, transform=transform, train=train, val=val, random_seed=random_seed)\n",
    "        print(f'num_images: {len(self.images)}')\n",
    "        self.attrs = attrs\n",
    "        self.class_dict = self._set_classes_attributes()\n",
    "        self.images, self.attr_indices = self._filter_images_by_attributes()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_path = os.path.join(self.bd.img_dir, self.images[idx]['filepath'])\n",
    "        image = Image.open(img_path)\n",
    "        if isinstance(self.attrs, str):\n",
    "            attr = self.images[idx]['attributes'][self.attr_indices[idx]]\n",
    "            label = self.class_dict[attr]\n",
    "            sample = {'image': image, 'label':label}\n",
    "        elif isinstance(self.attrs, list):\n",
    "            attrs = [self.images[idx]['attributes'][i] for i in self.attr_indices[idx]]\n",
    "            print(attrs)\n",
    "            labels = [self.class_dict[attr] for attr in attrs]\n",
    "            sample = {'image': image, 'labels':labels}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "        return sample\n",
    "    \n",
    "    def _set_classes_attributes(self):\n",
    "        pd_attr = pd.Series(self.bd.attributes)\n",
    "        if isinstance(self.attrs, str):\n",
    "            attrs_dict = pd_attr[pd_attr.str.contains(self.attrs)].to_dict()\n",
    "            class_dict = dict(zip(attrs_dict.values(), range(len(attrs_dict))))\n",
    "        elif isinstance(self.attrs, list):\n",
    "            attrs_dict = dict()\n",
    "            for attribute in self.attrs:\n",
    "                attr_dict = pd_attr[pd_attr.str.contains(attribute)].to_dict()\n",
    "                attrs_dict.update(attr_dict)\n",
    "            class_dict = dict(zip(attrs_dict.values(), range(len(attrs_dict))))\n",
    "        return class_dict\n",
    "    \n",
    "    def _filter_images_by_attributes(self):\n",
    "        filt_images = []\n",
    "        attr_indices = []\n",
    "        for img in self.images:\n",
    "            check=0\n",
    "            attr_index = []\n",
    "            for idx, attr in enumerate(img['attributes']):\n",
    "                if isinstance(self.attrs, str):\n",
    "                    if self.attrs in attr:\n",
    "                        filt_images.append(img)\n",
    "                        attr_indices.append(idx)\n",
    "                        break\n",
    "                elif isinstance(self.attrs, list):\n",
    "                    for attribute in self.attrs:\n",
    "                        if attribute in attr:\n",
    "                            check+=1\n",
    "#                             print(attribute)\n",
    "                            attr_index.append(idx)\n",
    "                    if check==len(self.attrs): # only append to images/indices if all attributes in self.attrs are in the images attributes\n",
    "                        if img not in filt_images:\n",
    "                            filt_images.append(img)\n",
    "                        else: pass\n",
    "#                             print('img already herre')\n",
    "#                         print('wowie')\n",
    "                        attr_indices.append(sorted(list(set(attr_index))))\n",
    "                else: raise(ValueError, \"self.attrs must be a string or a list of strings\")\n",
    "        return filt_images, attr_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16_bn(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [bd.images[i]['attributes'] for i in list(bd.images.keys()) if 'has_bill_shape' in bd.images[i]['attributes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_images: 1466\n",
      "num_images: 367\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_bird_dataset = Bird_Attribute_Loader(bd, attrs=['has_wing_color','has_bill_shape'], transform=trans, train=True)\n",
    "val_bird_dataset = Bird_Attribute_Loader(bd, attrs=['has_wing_color','has_bill_shape'], transform=trans, train=False, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_bird_dataset)\n",
    "# len(val_bird_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in train_bird_dataset:\n",
    "#     print(sample)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates a MTL model with the encoder from \"arch\" and with dropout multiplier ps.\n",
    "    \"\"\"\n",
    "    def __init__(self, model,ps=0.5):\n",
    "        super(MultiTaskModel,self).__init__()\n",
    "        \n",
    "#         num_feats = model.classifier[6].in_features\n",
    "#         features = list(model.classifier.children())[:-1]\n",
    "#         features.extend([nn.Linear(num_feats, len(train_bird_dataset.class_dict))])\n",
    "#         vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "        \n",
    "        self.encoder = model        #fastai function that creates an encoder given an architecture\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000, 9)    #fastai function that creates a head\n",
    "        self.fc2 = nn.Linear(1000, 15)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = nn.ReLU(self.encoder(x))\n",
    "        \n",
    "        bill_shape = self.fc1(x)\n",
    "        wing_color = self.fc2(x)\n",
    "\n",
    "        return bill_shape, wing_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskLossWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskLossWrapper, self).__init__()\n",
    "#         self.task_num = task_num\n",
    "#         self.log_vars = nn.Parameter(torch.zeros((task_num)))\n",
    "\n",
    "    def forward(self, preds, bill_shape, wing_color):\n",
    "\n",
    "\n",
    "        loss0 = nn.CrossEntropyLoss(preds[0], bill_shape)\n",
    "        loss1 = nn.CrossEntropyLoss(preds[1], wing_color)\n",
    "\n",
    "#         precision0 = torch.exp(-self.log_vars[0])\n",
    "#         loss0 = precision0*loss0 + self.log_vars[0]\n",
    "\n",
    "#         precision1 = torch.exp(-self.log_vars[1])\n",
    "#         loss1 = precision1*loss1 + self.log_vars[1]\n",
    "\n",
    "#         precision2 = torch.exp(-self.log_vars[2])\n",
    "#         loss2 = precision2*loss2 + self.log_vars[2]\n",
    "        \n",
    "        return loss0+loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskModel(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskModel(\n",
       "  (encoder): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (36): ReLU(inplace=True)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (39): ReLU(inplace=True)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1000, out_features=9, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        loss2 = crossEntropy(preds[2],ethnicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
